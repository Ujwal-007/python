{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75159eb3-42d9-494f-9793-c3ce47945666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training History:\n",
      " Epoch  Input 1  Input 2  Weight 1  Weight 2      Bias\n",
      "     1        1       -1  0.100000 -0.100000  0.100000\n",
      "     1        1        1 -0.010000 -0.210000 -0.010000\n",
      "     1       -1       -1  0.111000 -0.089000 -0.131000\n",
      "     1       -1        1 -0.022100  0.044100  0.002100\n",
      "     2        1       -1  0.084310 -0.062310  0.108510\n",
      "     2        1        1 -0.028741 -0.175361 -0.004541\n",
      "     2       -1       -1  0.091215 -0.055405 -0.124497\n",
      "     2       -1        1 -0.035897  0.071707  0.002615\n",
      "     3        1       -1  0.074602 -0.038792  0.113113\n",
      "     3        1        1 -0.040290 -0.153684 -0.001779\n",
      "     3       -1       -1  0.078929 -0.034465 -0.120998\n",
      "     3       -1        1 -0.044510  0.088974  0.002441\n",
      "     4        1       -1  0.068595 -0.024130  0.115545\n",
      "     4        1        1 -0.047406 -0.140131 -0.000456\n",
      "     4       -1       -1  0.071302 -0.021423 -0.119164\n",
      "     4       -1        1 -0.049887  0.099766  0.002025\n",
      "     5        1       -1  0.064876 -0.014997  0.116788\n",
      "     5        1        1 -0.051791 -0.131663  0.000121\n",
      "     5       -1       -1  0.066567 -0.013306 -0.118236\n",
      "     5       -1        1 -0.053244  0.106505  0.001574\n",
      "     6        1       -1  0.062573 -0.009312  0.117392\n",
      "     6        1        1 -0.054492 -0.126378  0.000327\n",
      "     6       -1       -1  0.063628 -0.008258 -0.117793\n",
      "     6       -1        1 -0.055340  0.110710  0.001175\n",
      "     7        1       -1  0.061147 -0.005778  0.117662\n",
      "     7        1        1 -0.056156 -0.123081  0.000359\n",
      "     7       -1       -1  0.061804 -0.005121 -0.117600\n",
      "     7       -1        1 -0.056649  0.113331  0.000852\n",
      "     8        1       -1  0.060264 -0.003582  0.117765\n",
      "     8        1        1 -0.057181 -0.121026  0.000320\n",
      "     8       -1       -1  0.060672 -0.003174 -0.117533\n",
      "     8       -1        1 -0.057466  0.114964  0.000605\n",
      "     9        1       -1  0.059717 -0.002218  0.117788\n",
      "     9        1        1 -0.057812 -0.119747  0.000259\n",
      "     9       -1       -1  0.059970 -0.001965 -0.117523\n",
      "     9       -1        1 -0.057976  0.115981  0.000423\n",
      "    10        1       -1  0.059377 -0.001373  0.117776\n",
      "    10        1        1 -0.058201 -0.118951  0.000198\n",
      "    10       -1       -1  0.059534 -0.001216 -0.117537\n",
      "    10       -1        1 -0.058294  0.116613  0.000292\n",
      "\n",
      "Truth Table:\n",
      "   Input 1  Input 2  Output\n",
      "0        1       -1      -1\n",
      "1        1        1       1\n",
      "2       -1       -1      -1\n",
      "3       -1        1       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class SimpleHebbianNeuron:\n",
    "    def __init__(self, input_dim, learning_rate=0.1, epochs=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(input_dim)\n",
    "        self.bias = 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        history = []\n",
    "        for epoch in range(self.epochs):\n",
    "            for xi, target in zip(X, y):\n",
    "                # Calculate output\n",
    "                output = np.dot(xi, self.weights) + self.bias\n",
    "                # Update weights and bias\n",
    "                self.weights += self.learning_rate * (target - output) * xi\n",
    "                self.bias += self.learning_rate * (target - output)\n",
    "                history.append([epoch + 1, xi[0], xi[1], self.weights[0], self.weights[1], self.bias])\n",
    "        \n",
    "        # Convert history to DataFrame for easier viewing\n",
    "        df_history = pd.DataFrame(history, columns=[\"Epoch\", \"Input 1\", \"Input 2\", \"Weight 1\", \"Weight 2\", \"Bias\"])\n",
    "        print(\"Training History:\")\n",
    "        print(df_history.to_string(index=False))\n",
    "        \n",
    "        return self.weights, self.bias\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for xi in X:\n",
    "            result = np.dot(xi, self.weights) + self.bias\n",
    "            predictions.append(1 if result > 0 else -1)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def create_truth_table(self, X, input_labels, output_label):\n",
    "        df = pd.DataFrame(X, columns=input_labels)\n",
    "        df[output_label] = self.predict(X)\n",
    "        return df\n",
    "\n",
    "# Example usage with XOR inputs and targets\n",
    "X = np.array([[1, -1], [1, 1], [-1, -1], [-1, 1]])\n",
    "y = np.array([1, -1, -1, 1])\n",
    "\n",
    "# Initialize and train the Hebbian neuron\n",
    "neuron = SimpleHebbianNeuron(input_dim=2, learning_rate=0.1, epochs=10)\n",
    "weights, bias = neuron.fit(X, y)\n",
    "\n",
    "# Generate and print the truth table\n",
    "input_labels = ['Input 1', 'Input 2']\n",
    "output_label = 'Output'\n",
    "truth_table = neuron.create_truth_table(X, input_labels, output_label)\n",
    "\n",
    "print(\"\\nTruth Table:\")\n",
    "print(truth_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785ed7e-ecd7-47e2-910c-6688bbbed5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
